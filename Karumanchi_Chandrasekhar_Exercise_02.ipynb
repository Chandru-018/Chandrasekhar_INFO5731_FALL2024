{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandru-018/Chandrasekhar_INFO5731_FALL2024/blob/main/Karumanchi_Chandrasekhar_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Research Question:\n",
        "How does the accuracy of predicting user behavior in e-commerce platforms vary with different machine learning algorithms?\n",
        "\n",
        " Data Collection:\n",
        "\n",
        "Types of Data Required:\n",
        "1. User Interaction Data:\n",
        "   - Clickstream data regarding the number of pages a user viewed and time spent on each page\n",
        "   - Purchase history of the items bought and the frequency of purchases\n",
        "   - User demographics: age, sex, location\n",
        "\n",
        "2. Product Information:\n",
        "   - Category of products\n",
        "Pricing information\n",
        "Product ratings and reviews\n",
        "3. Session Data:\n",
        "Time of visit\n",
        "Duration of session\n",
        "Devices used to access the site - mobile, desktop, tablet\n",
        "4. External Factors:\n",
        "Seasonal trends - knowing holidays and sales\n",
        "Marketing campaign data - ad clicked, promotions etc\n",
        "\n",
        "Quantiаtiоn оf Dаtа tо be Usеd:\n",
        "- The analyzed period, say 3 months, should at least have 10,000 user sessions.\n",
        "- Each session should have at least **50 interaction events** - clicks, views, etc.\n",
        "- There should be at least **1,000 unique users** for the consideration of a diverse sample.\n",
        "\n",
        "Steps for Data Collection:\n",
        "\n",
        "1. Defining the Scope\n",
        "   - Identify an e-commerce platform or industry.\n",
        "Identify the timeline required to collect data, such as Q1 of a particular year.\n",
        "\n",
        "2. Design Data Collection Framework:\n",
        "   Track the clickstream and session data by making use of tracking software. Example: Google Analytics, Mixpanel.\n",
        "   User demographics and interaction data could be stored in a database, for example, PostgreSQL and MongoDB.\n",
        "\n",
        "3. Data Extraction:\n",
        "APIs can utilize or export the features of the tracking software to gather data on user interactions.\n",
        "   - If available, employ user profile data from the database of the e-commerce platform.\n",
        "\n",
        "4. Data Integration:\n",
        "   - Integrate clickstream data into the database with user demographics and product information.\n",
        "   - Cleaning and preprocessing: handle missing values and outliers in the data.\n",
        "\n",
        "5. Data Privacy Compliance:\n",
        "- Ensure that the data is anonymized to ensure it complies with GDPR or CCPA.\n",
        "   - If tracking information about Personally Identifiable Information, obtain any necessary permissions.\n",
        "\n",
        "6. Save Data\n",
        "   - Store data into a structured format like CSV or JSON to save in a secure cloud storage facility like AWS S3.\n",
        "   - Schedule regular backups and do version control to keep track of changes done to the data.\n",
        "\n",
        "Data Analysis:\n",
        "\n",
        "1. Preprocessing:\n",
        "- Preprocessing: clean and transform the data into a decent analytical format.\n",
        "   Normalize features, like user demographics and session duration.\n",
        "\n",
        "2. Algorithm Selection:\n",
        "   - The selection will be done from a set of machine learning algorithms such as logistic regression, decision trees, random forests, and neural networks.\n",
        "\n",
        "3. Model Training:\n",
        "   - Split the data into training and testing, with 80% going to training and 20% to testing, for example.\n",
        "- Train each model using the training set, followed by evaluating its performance using accuracy, precision, recall, and F1-score.\n",
        "\n",
        "4. Comparison and Insights:\n",
        "   - The performance comparison of each algorithm will output which algorithm is best for predicting the behavior of the user.\n",
        "   - Visualize findings using appropriate visualization libraries, such as matplotlib and seaborn.\n",
        "\n",
        "5. Reporting:\n",
        "Provide a summary report of the results, highlighting the top-performing algorithms along with actionable insights that will provide more user engagement and sales.\n",
        "\n",
        "Conclusion:\n",
        "It also looks into the effectiveness of various algorithms in machine learning for predicting user behavior and further provides actionable insights to e-commerce platforms so as to enhance user experiences and thereby raise sales. Researchers following the steps of data collection and analysis can systematically and ethically obtain meaningful insights from user interactions."
      ],
      "metadata": {
        "id": "cikVKDXdTbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Constants\n",
        "num_samples = 1000\n",
        "age_groups = ['18-24', '25-34', '35-44', '45-54', '55+']\n",
        "genders = ['Male', 'Female', 'Other']\n",
        "products = ['Electronics', 'Fashion', 'Home', 'Books', 'Sports']\n",
        "\n",
        "# Generate user demographics\n",
        "ages = np.random.choice(age_groups, size=num_samples)\n",
        "genders = np.random.choice(genders, size=num_samples)\n",
        "locations = np.random.choice(['North America', 'Europe', 'Asia', 'South America'], size=num_samples)\n",
        "\n",
        "# Generate session data\n",
        "session_ids = np.arange(1, num_samples + 1)\n",
        "session_durations = np.random.randint(1, 300, size=num_samples)  # Duration in seconds\n",
        "num_clicks = np.random.randint(1, 20, size=num_samples)  # Number of clicks in a session\n",
        "\n",
        "# Generate interaction data\n",
        "purchased_product = np.random.choice(products, size=num_samples)\n",
        "purchase_made = np.random.choice([0, 1], size=num_samples, p=[0.7, 0.3])  # 30% chance of making a purchase\n",
        "\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'session_id': session_ids,\n",
        "    'age_group': ages,\n",
        "    'gender': genders,\n",
        "    'location': locations,\n",
        "    'session_duration': session_durations,\n",
        "    'num_clicks': num_clicks,\n",
        "    'purchased_product': purchased_product,\n",
        "    'purchase_made': purchase_made  # Target variable\n",
        "})\n",
        "\n",
        "# Save dataset to a CSV file\n",
        "data.to_csv('ecommerce_user_behavior_dataset.csv', index=False)\n",
        "\n",
        "print(\"Dataset generated and saved as 'ecommerce_user_behavior_dataset.csv'\")\n"
      ],
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9f49a5-d43c-46ad-e290-53f698a71018"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated and saved as 'ecommerce_user_behavior_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaGLbSHHB8Ej"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKskTzbCLaU"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write your response here.\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}